{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9699761,"sourceType":"datasetVersion","datasetId":5931322}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SUMMARIZING PAPERS CONTAINS TWO PARTS:-\n- EXTRACTING TEXT FROM PDF/WORD FILE\n- SUMMARIZING TEXT(EXTRACTIVE/ABSTRACTIVE)","metadata":{}},{"cell_type":"markdown","source":"# INSTALLING LIBRARIES","metadata":{}},{"cell_type":"code","source":"!pip install pdfplumber\n!pip install python-docx\n!pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:14:44.284007Z","iopub.execute_input":"2024-10-23T13:14:44.284692Z","iopub.status.idle":"2024-10-23T13:15:22.636909Z","shell.execute_reply.started":"2024-10-23T13:14:44.284649Z","shell.execute_reply":"2024-10-23T13:15:22.635776Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\nCollecting python-docx\n  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from python-docx) (5.3.0)\nRequirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from python-docx) (4.12.2)\nDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: python-docx\nSuccessfully installed python-docx-1.1.2\nCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## EXTRACTING TEXT FROM A WORD/PDF FILE\n- We have two options for extracting text from pdf :- PyPDF2 and pdfplumber\n- We are using pdfplumber library of Python rather than PyPDF2 because it retains some of the original formatting of the documents like table,bullet points,etc which are not retained by PyPDF2\n- We will extract text from word file using docx library","metadata":{}},{"cell_type":"code","source":"import pdfplumber\nfrom docx import Document\nimport os\n\n# Function to extract text from PDF\ndef extract_text_from_pdf(pdf_path):\n    print(\"Provided Document is PDF file\\n\\n\")\n    extracted_text = \"\"\n    try:\n        with pdfplumber.open(pdf_path) as pdf:\n            for page_num, page in enumerate(pdf.pages):\n                extracted_text += page.extract_text()\n    except Exception as e:\n        print(f\"Error reading PDF file: {e}\")\n    return extracted_text\n\n# Function to extract text from Word (.docx)\ndef extract_text_from_docx(docx_path):\n    print(\"Provided Document is Word file\\n\\n\")\n    extracted_text = \"\"\n    try:\n        doc = Document(docx_path)\n        extracted_text = '\\n'.join([para.text for para in doc.paragraphs])\n    except Exception as e:\n        print(f\"Error reading DOCX file: {e}\")\n    return extracted_text\n\n# Function to handle both PDF and Word files\ndef extract_text_from_file(file_path):\n    _, file_extension = os.path.splitext(file_path)\n    \n    if file_extension.lower() == '.pdf':\n        return extract_text_from_pdf(file_path)\n    elif file_extension.lower() == '.docx':\n        return extract_text_from_docx(file_path)\n    else:\n        return f\"Unsupported file format: {file_extension}\"\n\n\n# path\npath = '/kaggle/input/papers/SegNet Network Architecture for Deep Learning Image.pdf'\n\n# Extract text based on file type\nextracted_text = extract_text_from_file(path)\n\n# Print extracted text\n# print(\"Extracted Text is: \\n\" )\n# print(extracted_text)\n\n\ntokens = len(extracted_text.split())\nprint(f'No of tokens in text: {tokens}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:49.228592Z","iopub.execute_input":"2024-10-23T13:29:49.229222Z","iopub.status.idle":"2024-10-23T13:29:51.093649Z","shell.execute_reply.started":"2024-10-23T13:29:49.229182Z","shell.execute_reply":"2024-10-23T13:29:51.092544Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Provided Document is PDF file\n\n\nNo of tokens in text: 3205\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation Metrix ROGUE\n\nfrom rouge import Rouge\n\n\nrouge = Rouge()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:51.094995Z","iopub.execute_input":"2024-10-23T13:29:51.095346Z","iopub.status.idle":"2024-10-23T13:29:51.100196Z","shell.execute_reply.started":"2024-10-23T13:29:51.095307Z","shell.execute_reply":"2024-10-23T13:29:51.099145Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# # Sample Text for Summary Generation on all models\n# extracted_text = \"\"\"The Role of Renewable Energy in Sustainable Development\n# The pursuit of sustainable development has become one of the most pressing challenges of our time. As the global population continues to rise and the demand for energy increases, the reliance on fossil fuels poses significant environmental and economic threats. In this context, renewable energy sources have emerged as a viable alternative, offering a path toward sustainable and environmentally friendly energy solutions.\n\n# 1. Understanding Renewable Energy\n\n# Renewable energy refers to energy derived from resources that are naturally replenished, such as sunlight, wind, rain, tides, waves, and geothermal heat. Unlike fossil fuels, which are finite and contribute to greenhouse gas emissions, renewable energy sources provide a cleaner and more sustainable energy supply. Solar power, for instance, harnesses sunlight using photovoltaic cells to generate electricity, while wind energy converts the kinetic energy of wind into power through turbines.\n\n# 2. Environmental Benefits\n\n# The transition to renewable energy plays a crucial role in mitigating climate change. According to the Intergovernmental Panel on Climate Change (IPCC), adopting renewable energy could significantly reduce global greenhouse gas emissions, which are responsible for global warming and climate instability. By reducing our reliance on coal, oil, and natural gas, we can decrease air pollution, leading to improved public health outcomes and a reduction in healthcare costs associated with pollution-related illnesses.\n\n# 3. Economic Opportunities\n\n# Investing in renewable energy not only benefits the environment but also creates substantial economic opportunities. The renewable energy sector has been a significant source of job creation, often outpacing traditional fossil fuel industries. In 2020, the International Renewable Energy Agency (IRENA) reported that the renewable energy sector employed over 11 million people worldwide, with jobs expected to increase as more countries commit to sustainable energy goals.\n\n# 4. Energy Security and Independence\n\n# Renewable energy also enhances energy security and independence. By diversifying energy sources, countries can reduce their reliance on imported fuels, which can be subject to price volatility and geopolitical tensions. For instance, countries that invest in solar and wind energy can harness their local resources, leading to greater energy autonomy. This not only stabilizes energy prices but also enhances national security by reducing vulnerability to external energy supply disruptions.\n\n# 5. Challenges and Considerations\n\n# Despite the numerous advantages, the transition to renewable energy is not without challenges. Issues such as the intermittent nature of renewable sources—like solar and wind—require the development of energy storage technologies and grid management solutions. Furthermore, the initial investment costs for renewable energy infrastructure can be high, although these costs have been decreasing rapidly due to technological advancements and economies of scale.\n\n# 6. Conclusion\n\n# In conclusion, renewable energy represents a critical component of a sustainable future. By reducing greenhouse gas emissions, creating jobs, enhancing energy security, and providing clean power, renewable energy sources can significantly contribute to sustainable development. Policymakers, businesses, and individuals must work collaboratively to overcome existing challenges and accelerate the transition toward a greener, more sustainable energy landscape. As we move forward, embracing renewable energy will be essential in addressing the global challenges of climate change, economic inequality, and energy insecurity.\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:51.102906Z","iopub.execute_input":"2024-10-23T13:29:51.103265Z","iopub.status.idle":"2024-10-23T13:29:51.114116Z","shell.execute_reply.started":"2024-10-23T13:29:51.103229Z","shell.execute_reply":"2024-10-23T13:29:51.113067Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## ABSTRACTIVE SUMMARIZATION","metadata":{}},{"cell_type":"markdown","source":"### It generates a summary by creating new sentences that capture the meaning of the original text, rather than extracting exact phrases or sentences.","metadata":{}},{"cell_type":"markdown","source":"### We can paraphrase the output text for better understanding ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ndevice = \"cpu\"\n\nparaphrase_tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n\nparaphrase_model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n\ndef paraphrase(\n    question,\n    num_beams=5,\n    num_beam_groups=5,\n    num_return_sequences=5,\n    repetition_penalty=10.0,\n    diversity_penalty=3.0,\n    no_repeat_ngram_size=2,\n    temperature=0.7,\n    max_length=128\n):\n    input_ids = paraphrase_tokenizer(\n        f'paraphrase: {question}',\n        return_tensors=\"pt\", padding=\"longest\",\n        max_length=max_length,\n        truncation=True,\n    ).input_ids.to(device)\n    \n    outputs = paraphrase_model.generate(\n        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n        num_beams=num_beams, num_beam_groups=num_beam_groups,\n        max_length=max_length, diversity_penalty=diversity_penalty\n    )\n\n    res = paraphrase_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    \n    \n\n    return res","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:51.115151Z","iopub.execute_input":"2024-10-23T13:29:51.115465Z","iopub.status.idle":"2024-10-23T13:29:53.230164Z","shell.execute_reply.started":"2024-10-23T13:29:51.115433Z","shell.execute_reply":"2024-10-23T13:29:53.229295Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Based on number of tokens in the extracted text we will choose the model which is best for that particular task.\n- upto 1024 token :- BART(fine-tuned on CNN-Dailymail) AND PEGASUS(fine-tuned on CNN-Dailymail and various other)\n- upto 4096 tokens :-  LONGT5(Pre-Trained on C4)\n- upto 16,384 tokens :-Longformer (Encoder and Decoder) (fine-tuned on ArXiv and Pubmed)","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM \nfrom transformers import LEDForConditionalGeneration, LEDTokenizer\nimport torch\nfrom transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.231312Z","iopub.execute_input":"2024-10-23T13:29:53.231639Z","iopub.status.idle":"2024-10-23T13:29:53.236607Z","shell.execute_reply.started":"2024-10-23T13:29:53.231605Z","shell.execute_reply":"2024-10-23T13:29:53.235537Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"summaries = {}","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.237832Z","iopub.execute_input":"2024-10-23T13:29:53.238153Z","iopub.status.idle":"2024-10-23T13:29:53.247614Z","shell.execute_reply.started":"2024-10-23T13:29:53.238119Z","shell.execute_reply":"2024-10-23T13:29:53.246576Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# BART Large\ndef summarize_with_bart_large(extracted_text):\n    bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n    bart_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n    summarizer = pipeline(\"summarization\", model=bart_model, tokenizer=bart_tokenizer, clean_up_tokenization_spaces=True)\n    \n    summarized_text = summarizer(extracted_text)\n    \n    \n    \n    paraphrased = paraphrase(summarized_text[0][\"summary_text\"])\n    \n    bart_paraphrased = ' '.join(paraphrased)\n    \n    \n    summaries['BART'] = summarized_text[0][\"summary_text\"]\n    \n    bart_score = rouge.get_scores(extracted_text , summarized_text[0][\"summary_text\"])\n    \n    \n    \n    summaries['BART PARAPHRASED'] = bart_paraphrased\n    \n    summaries['BART ROUGE SCORES'] = bart_score\n    \n    \n    print(\"Summary and Rouge scores and saved\")\n#     print(f'BART Summarized Text:- {summarized_text[0][\"summary_text\"]}\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.248701Z","iopub.execute_input":"2024-10-23T13:29:53.249027Z","iopub.status.idle":"2024-10-23T13:29:53.258975Z","shell.execute_reply.started":"2024-10-23T13:29:53.248993Z","shell.execute_reply":"2024-10-23T13:29:53.258103Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Pegasus Large\ndef summarize_with_pegasus_large(extracted_text):\n    pegasus_tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-large\")\n    pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-large\")\n    summarizer = pipeline(\"summarization\", model=pegasus_model, tokenizer=pegasus_tokenizer, clean_up_tokenization_spaces=True)\n    \n    summarized_text = summarizer(extracted_text)\n    \n    \n    paraphrased = paraphrase(summarized_text[0][\"summary_text\"])\n    \n    pegasus_paraphrased = ' '.join(paraphrased)\n    \n    pegasus_score = rouge.get_scores(extracted_text , summarized_text[0][\"summary_text\"])\n    \n    \n    summaries['PEGASUS'] = summarized_text[0][\"summary_text\"]\n    \n    summaries['PEGASUS PARAPHRASED'] = pegasus_paraphrased\n    \n    summaries['PEGASUS ROUGE SCORES'] = pegasus_score\n    \n    print(\"Summary and Rouge score are saved\")\n#     print(f'PEGASUS Summarized Text:- {summarized_text[0][\"summary_text\"]}\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.260269Z","iopub.execute_input":"2024-10-23T13:29:53.260860Z","iopub.status.idle":"2024-10-23T13:29:53.272475Z","shell.execute_reply.started":"2024-10-23T13:29:53.260825Z","shell.execute_reply":"2024-10-23T13:29:53.271374Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# LongT5\ndef summarize_with_longt5(extracted_text):\n    longt5_tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-tglobal-base\")\n    longt5_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/long-t5-tglobal-base\")\n    summarizer = pipeline(\"summarization\", model=longt5_model, tokenizer=longt5_tokenizer, clean_up_tokenization_spaces=True)\n    \n    summarized_text = summarizer(extracted_text)\n    \n    \n    paraphrased = paraphrase(summarized_text[0][\"summary_text\"])\n    \n    longt5_paraphrased = ' '.join(paraphrased)\n    \n    long_t5_score = rouge.get_scores(extracted_text , summarized_text[0][\"summary_text\"])\n    \n    \n    summaries['LONGT5'] = summarized_text[0][\"summary_text\"]\n    \n    summaries['LONGT5 PARAPHRASED'] = longt5_paraphrased\n    \n    summaries['LONGT5 ROUGE SCORES'] = long_t5_score\n    \n    print(\"Summary and Rouge scores are saved\")\n#     print(f'LongT5 Summarized Text:- {summarized_text[0][\"summary_text\"]}\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.275443Z","iopub.execute_input":"2024-10-23T13:29:53.275780Z","iopub.status.idle":"2024-10-23T13:29:53.282596Z","shell.execute_reply.started":"2024-10-23T13:29:53.275740Z","shell.execute_reply":"2024-10-23T13:29:53.281661Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def summarize_with_bigbird_pegasus(extracted_text):\n        tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n\n        # by default encoder-attention is `block_sparse` with num_random_blocks=3, block_size=64\n        model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n\n        # decoder attention type can't be changed & will be \"original_full\"\n        # you can change `attention_type` (encoder only) to full attention like this:\n        model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", attention_type=\"original_full\")\n\n        # you can change `block_size` & `num_random_blocks` like this:\n        model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", block_size=16, num_random_blocks=2)\n\n        \n        inputs = tokenizer(extracted_text, return_tensors='pt' , padding=False)\n        prediction = model.generate(**inputs)\n        prediction = tokenizer.batch_decode(prediction)\n        \n        \n        paraphrased = paraphrase(prediction[0])\n    \n        bigbird_paraphrased = ' '.join(paraphrased)\n    \n    \n        bigbird_score = rouge.get_scores(extracted_text , prediction[0])\n    \n        summaries['BIGBIRD'] = prediction[0]\n        \n        summaries['BIGBIRD PARAPHRASED'] = bigbird_paraphrased\n        \n        summaries['BIGBIRD ROGUE SCORES'] = bigbird_score\n        \n        print(\"Summary and Rouge scores are saved\")\n#         print(f\"BIGBIRD Summarized Text: {prediction}\")\n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.283737Z","iopub.execute_input":"2024-10-23T13:29:53.284033Z","iopub.status.idle":"2024-10-23T13:29:53.296739Z","shell.execute_reply.started":"2024-10-23T13:29:53.284001Z","shell.execute_reply":"2024-10-23T13:29:53.295912Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# LED (Longformer Encoder-Decoder)\ndef summarize_with_led_large(extracted_text):\n    tokenizer = LEDTokenizer.from_pretrained(\"allenai/led-large-16384-arxiv\")\n\n    input_ids = tokenizer(extracted_text, return_tensors=\"pt\" , padding=False).input_ids\n    global_attention_mask = torch.zeros_like(input_ids)\n    # set global_attention_mask on first token\n    global_attention_mask[:, 0] = 1\n\n    model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-large-16384-arxiv\", return_dict_in_generate=True)\n\n    sequences = model.generate(input_ids, global_attention_mask=global_attention_mask).sequences\n\n    summary = tokenizer.batch_decode(sequences)\n    \n    paraphrased = paraphrase(summary[0])\n    \n    \n    led_paraphrased = ' '.join(paraphrased)\n    \n    \n    led_score = rouge.get_scores(extracted_text , summary[0])\n\n    summaries[\"LED\"] = summary[0]\n    \n    summaries['LED PARAPHRASED'] = led_paraphrased\n    \n    summaries['LED ROUGE SCORES'] = led_score\n    \n    print(\"Summary and rouge scores are saved\")\n    \n#     print(f'LED LARGE Summarized Text: {summary}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.297895Z","iopub.execute_input":"2024-10-23T13:29:53.298169Z","iopub.status.idle":"2024-10-23T13:29:53.311555Z","shell.execute_reply.started":"2024-10-23T13:29:53.298125Z","shell.execute_reply":"2024-10-23T13:29:53.310665Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Checking for each models if they can summarize","metadata":{}},{"cell_type":"code","source":"# BART\nbart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\ntokenized_output = bart_tokenizer(extracted_text)\nbart_tokens = len(tokenized_output[0])\n\nprint(f'BART TOKENIZED LENGTH: {bart_tokens}')\nif bart_tokens <= 1024:\n    print(\"Generating Summary...\")\n    summarize_with_bart_large(extracted_text)\nelse:\n    print(\"BART can not be used here\")\n\n# Pegasus\npegasus_tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-large\")\ntokenized_output = pegasus_tokenizer(extracted_text)\npegasus_tokens = len(tokenized_output[0])\n\nprint(f'PEGASUS TOKENIZED LENGTH: {pegasus_tokens}')\nif pegasus_tokens <= 1024:\n    print(\"Generating Summary...\")\n    summarize_with_pegasus_large(extracted_text)\nelse:\n    print(\"PEGASUS can not be used here\")\n\n\n# LongT5\nlongt5_tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-tglobal-base\")\ntokenized_output = longt5_tokenizer(extracted_text)\nlongt5_tokens = len(tokenized_output[0])\n\nprint(f'LONGT5 TOKENIZED LENGTH: {longt5_tokens}')\nif longt5_tokens <= 4096:\n    print(\"Generating Summary...\")\n    summarize_with_longt5(extracted_text)\nelse:\n    print(\"LONGT5 can not be used here\")\n\n# BIGBIRD\nbigbird_tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\ntokenized_output = bigbird_tokenizer(extracted_text, return_tensors=\"pt\")\nbigbird_tokens = tokenized_output['input_ids'].shape[1]\n\n\nprint(f'BIGBIRD TOKENIZED LENGTH: {bigbird_tokens}')\nif bigbird_tokens <= 4096:\n    print(\"Generating Summary...\")\n    summarize_with_bigbird_pegasus(extracted_text)\nelse:\n    print(\"BIGBIRD cannot be used here\")\n\n# LED (Longformer Encoder-Decoder)\nled_tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\ntokenized_output = led_tokenizer(extracted_text)\nled_tokens = len(tokenized_output[0])\n\nprint(f'LED TOKENIZED LENGTH: {led_tokens}')\nif led_tokens <= 16384:# LED can handle even longer sequences\n    print(\"Generating Summary...\")\n    summarize_with_led_large(extracted_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:29:53.312967Z","iopub.execute_input":"2024-10-23T13:29:53.313413Z","iopub.status.idle":"2024-10-23T13:31:43.530142Z","shell.execute_reply.started":"2024-10-23T13:29:53.313370Z","shell.execute_reply":"2024-10-23T13:31:43.529174Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"BART TOKENIZED LENGTH: 5473\nBART can not be used here\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (4645 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"PEGASUS TOKENIZED LENGTH: 4645\nPEGASUS can not be used here\nLONGT5 TOKENIZED LENGTH: 5498\nLONGT5 can not be used here\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (4645 > 4096). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"BIGBIRD TOKENIZED LENGTH: 4645\nBIGBIRD cannot be used here\nLED TOKENIZED LENGTH: 5473\nGenerating Summary...\n","output_type":"stream"},{"name":"stderr","text":"Input ids are automatically padded from 5473 to 6144 to be a multiple of `config.attention_window`: 1024\n","output_type":"stream"},{"name":"stdout","text":"Summary and rouge scores are saved\n","output_type":"stream"}]},{"cell_type":"code","source":"for model in summaries:\n  print(model.upper())\n  print(summaries[model])\n  print(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:31:43.532087Z","iopub.execute_input":"2024-10-23T13:31:43.532423Z","iopub.status.idle":"2024-10-23T13:31:43.537499Z","shell.execute_reply.started":"2024-10-23T13:31:43.532387Z","shell.execute_reply":"2024-10-23T13:31:43.536572Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"LED\n</s> image segmentation is a crucial task in computer vision , with applications ranging from autonomous driving to medical image analysis. in recent years , deep learning has revolutionized this field , leading to the development of various neural network models aimed at improving segmentation accuracy . \n one such architecture is SegNet , which we explore in this article. \n SegNet consists of an encoder network , a corresponding decoder network , and a pixel-wise classification layer . \n it can be trained end-to-end using stochastic gradient descent (SGD ) optimization . \n the innovation lies in the decoder network s approach to upsampling , utilizing pooled indices from the encoder s maximum pooling step to perform nonlinear up sampling . \n this eliminates the need for additional learning during up sampling , making SegNet efficient in both storage and computation . \n furthermore , it can achieve similar segmentation performance to traditional methods while reducing computational complexity . \n its potential for real-time applications makes it a valuable tool in the field of computer vision with promising integrated applications and prospects . </s>\n\nLED PARAPHRASED\nThe use of segmentation in computer vision has become increasingly prevalent, with applications such as autonomous driving and medical image analysis utilizing neural networks. SegNet, which includes an encoder network, decoder system, and a pixel-wise classification layer, is one of the many architectures that can be used to train end-to-end training using stochastic gradient descent (SGD). Several neural network models have been created in recent years to improve segmentation accuracy in computer vision, including SegNet, which is a complex combination of an encoder network, decoder networks, and pixel-wise classification layer. It can be trained using stochastic gradient descent (SGD) from beginning to end. SegNet, a neural network architecture that includes an encoder network, decoder networks, and pixel-wise classification layer, is primarily used for image segmentation in computer vision applications. Segmentation is a vital area of computer vision, and it has been revolutionized by the integration of deep learning technologies, leading to the creation of neural network architectures that aim to improve segmentation accuracy. SegNet, which includes an encoder network with corresponding decoder layer and pixel-wise classification layer, can be trained using stochastic gradient descent (SGD) from beginning to end. In recent years, computer vision has transformed into a field that emphasizes segmentation, with SegNet being an example of . It features an encoder network, enabling the classification of images in real-time, as well as analyzing them using stochastic gradient descent (SGD), making it scalable for large datasets or data sets.\n\nLED ROUGE SCORES\n[{'rouge-1': {'r': 0.9469026548672567, 'p': 0.09029535864978903, 'f': 0.1648690276862472}, 'rouge-2': {'r': 0.7195121951219512, 'p': 0.045932269365511876, 'f': 0.08635199301749874}, 'rouge-l': {'r': 0.9292035398230089, 'p': 0.08860759493670886, 'f': 0.16178736358763396}}]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EXTRACTIVE SUMMARIZATION","metadata":{}},{"cell_type":"markdown","source":"## It selects key sentences or phrases from the original text to form a concise summary without altering the original content.","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nnltk.download('stopwords')\nstopwords = set(stopwords.words('english'))\nnltk.download('punkt')\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:31:43.538649Z","iopub.execute_input":"2024-10-23T13:31:43.538971Z","iopub.status.idle":"2024-10-23T13:31:43.554599Z","shell.execute_reply.started":"2024-10-23T13:31:43.538939Z","shell.execute_reply":"2024-10-23T13:31:43.553692Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom string import punctuation\nimport networkx as nx\n\n# Initialize stopwords\nstop_words = list(stopwords.words('english'))\n\n# Preprocess text\ntext = ' '.join(extracted_text.split())  # Remove extra whitespace\noriginal_sentences = sent_tokenize(text)\n\n# Clean sentences\ncleaned_sentences = []\nfor sentence in original_sentences:\n    # Convert to lowercase and remove punctuation\n    cleaned = sentence.lower()\n    cleaned = ''.join(char for char in cleaned if char not in punctuation)\n    cleaned_sentences.append(cleaned)\n\n# Calculate TF-IDF matrix. It will generate a matrix where each row represent a sentence and coloumn represent a term\ntfidf = TfidfVectorizer(stop_words=stop_words)\ntfidf_matrix = tfidf.fit_transform(cleaned_sentences)\n\n# Calculate similarity matrix between sentences\nsimilarity_matrix = (tfidf_matrix * tfidf_matrix.T).toarray()\n\n# Calculate TextRank scores\nnx_graph = nx.from_numpy_array(similarity_matrix)\ntextrank_scores = nx.pagerank(nx_graph, alpha=0.85, max_iter=50)\n\n# Calculate position scores which should be higher for starting and ending\nnum_sentences = len(original_sentences)\npositions = np.arange(num_sentences)\nmiddle = num_sentences // 2\nposition_scores = 1 - np.minimum(positions, num_sentences - 1 - positions) / middle\n\n# Combine scores (0.7 weight for TextRank, 0.3 for position)\nfinal_scores = {}\nfor idx in range(num_sentences):\n    final_scores[idx] = 0.7 * textrank_scores[idx] + 0.3 * position_scores[idx]\n\n# Select top sentences\nmin_sentences = 3\nratio = 0.3\nnum_sentences = max(min_sentences, int(len(original_sentences) * ratio))\n\n# Sort sentences by score and get top ones\nselected_indices = sorted(sorted(final_scores.items(), key=lambda x: x[1], reverse=True)[:num_sentences])\n\n# Create summary maintaining original sentence order\nsummary_sentences = [original_sentences[idx] for idx, _ in selected_indices]\nsummary = ' '.join(summary_sentences)\n\n\nextractive_score = rouge.get_scores(extracted_text , summary)\n\n# Print results\nprint(\"Original Text Length:\", len(text))\nprint(\"Summary Length:\", len(summary))\nprint(\"\\nSummary:\\n\", summary)\n\n\nprint(f'Rouge Scores are {extractive_score}')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T13:31:43.555967Z","iopub.execute_input":"2024-10-23T13:31:43.556326Z","iopub.status.idle":"2024-10-23T13:31:48.638721Z","shell.execute_reply.started":"2024-10-23T13:31:43.556283Z","shell.execute_reply":"2024-10-23T13:31:48.637814Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Original Text Length: 22799\nSummary Length: 7197\n\nSummary:\n Academic Journal of Science and Technology ISSN: 2771-3032 | Vol. 9, No. 2, 2024 SegNet Network Architecture for Deep Learning Image Segmentation and Its Integrated Applications and Prospects Chenwei Zhang1, *, Wenran Lu2, Jiang Wu3, Chunhe Ni4, Hongbo Wang5 1Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA 2Electrical Engineering, University of Texas at Austin, Austin, TX, USA 3Computer Science, University of Southern California, Los Angeles, CA, USA 4Computer Science, University of Texas at Dallas, Richardson, TX, USA 5Computer Science, University of Southern California, Los Angeles, CA, USA * Corresponding author: zchenwei66@gmail.com Abstract: Semantic image segmentation is a crucial task in computer vision, with applications ranging from autonomous driving to medical image analysis. In recent years, deep learning has revolutionized this field, leading to the development of various neural network models aimed at improving segmentation accuracy. One such architecture is SegNet, which we explore in this article.SegNet's architecture consists of an encoder network, a corresponding decoder network, and a pixel-wise classification layer. The encoder network, resembling VGG16 with 13 convolutional layers, extracts high-level features from input images. The innovation lies in the decoder network's approach to upsampling, utilizing pooled indices from the encoder's maximum pooling step to perform non-linear up sampling. This eliminates the need for additional learning during up sampling, making SegNet efficient in both storage and computation.SegNet represents an exciting advancement in deep learning image segmentation. Its efficient architecture, memory-conscious design, and potential for real-time applications make it a valuable tool in the field of computer vision with promising integrated applications and prospects. Keywords: SegNet, Image segmentation, Deep learning, Computer vision. LargeFOV and DeconvNet. This comparison reveals the 1. Introduction trade-off between memory usage and segmentation accuracy, In recent years, with the widespread popularity of deep highlighting the importance of balancing these factors to learning, numerous scholars have proposed various semantic achieve optimal segmentation performance. segmentation algorithms based on different neural network SegNet was primarily inspired by applications related to models to enhance the accuracy of semantic segmentation. scenario understanding. As a result, it was designed to be Semantic segmentation, a fundamental topic in computer efficient in terms of both storage and computation time during vision, aims to assign semantic labels to each pixel in an inference. Additionally, it boasts a significantly smaller image. Deep convolutional neural networks, particularly number of trainable parameters compared to competing those based on fully convolutional neural networks, have architectures, and it can be trained end-to-end using stochastic demonstrated significant improvements over traditional gradient descent (SGD) optimization.Overall, SegNet systems that rely on manually crafted features. represents a notable advancement in semantic segmentation, The core of a trainable segmentation engine typically offering an efficient and effective approach for various comprises an encoder network, a corresponding decoder computer vision tasks. network, and a pixel-by-pixel classification layer. The 2. Related Work encoder network's architecture is topologically similar to that of the VGG16 network, consisting of 13 convolutional layers. \"SegNet draws inspiration from scenario understanding The decoder network is responsible for mapping the low- applications, and as such, it is meticulously designed to excel resolution encoder feature map back to the full input in both storage and computational efficiency during inference. resolution feature map for pixel-wise classification. Furthermore, it boasts significantly fewer trainable One of the noteworthy innovations introduced by SegNet parameters compared to competing architectures and can be is the approach it uses for upsampling the lower-resolution trained end-to-end using stochastic gradient descent. We input feature map in the decoder. Specifically, the decoder conducted controlled benchmark tests of SegNet and other performs nonlinear upsampling by using the pooled index architectures in road scene and SUN RGB-D indoor scene calculated during the maximum pooling step of the segmentation tasks. These quantitative evaluations corresponding encoder. This method eliminates the need for demonstrate that, in comparison to other architectures, additional learning during the upsampling process. The SegNet offers excellent performance while maintaining upsampled map is sparse and is then convolved with a competitive inference times and highly efficient inference trainable filter to generate a dense feature map. storage.\" To evaluate the proposed architecture's performance, we conducted a comparison with widely used techniques such as 2.1. SegNet semantic segmentation FCN, as well as well-known architectures like DeepLab- SegNet consists of a network of encoders and a network of 224decoders, both of which are convolutional networks. The Since SegNet uses parameters only in the encoder and pooled encoder network is typically extracted from a pre-trained indexes in the decoder for non-learning upsampling, it has VGG16 network with its fully connected layer removed. Journal of Learning Algorithms.\" arXiv preprint Theory and Practice of Engineering Science, vol. 3, no. 12, Dec. arXiv:2312.12872 (2023). 2023, pp. 1-6, doi:10.53469/jtpes.2023.03(12).01. [15] Liu, Bo, et al. \"Integration and Performance Analysis of [21] Xin, Q., He, Y., Pan, Y., Wang, Y., & Du, S. (2023). The Artificial Intelligence and Computer Vision Based on Deep implementation of an AI-driven advertising push system based Learning Algorithms.\" arXiv preprint on a NLP algorithm. International Journal of Computer Science arXiv:2312.12872 (2023). and Information Technology, 1(1), 30-37.0 [16] Yu, L., Liu, B., Lin, Q., Zhao, X., & Che, C. (2024). Semantic [22] Pan, Yiming, et al. “Application of Three-Dimensional Coding Similarity Matching for Patent Documents Using Ensemble Network in Screening and Diagnosis of Cervical Precancerous BERT-related Model and Novel Text Processing Lesions”. Frontiers in Computing and Intelligent Systems, vol. Method. arXiv preprint arXiv:2401.06782. 6, no. 3, Jan. 2024, pp. 61-64, https://doi.org/10.54097/mi3VM0yB. [17] “The Application of Artificial Intelligence to The Bayesian Model Algorithm for Combining Genome Data”. Academic [23] “Enhancing Computer Digital Signal Processing through the Journal of Science and Technology, vol. 8, no. 3, Dec. 2023, Utilization of RNN Sequence Algorithms”. International pp. 132-5, https://doi.org/10.54097/ykhccb53. Journal of Computer Science and Information Technology, vol. 1, no. 1, Dec. 2023, pp. 60-68, [18] Jin, Keyan. \"Impacts of Word of Mouth (WOM) on E-Business https://doi.org/10.62051/ijcsit.v1n1.09. Online Pricing.\" JGIM vol.31, no.3 2023: pp.1-17. http://doi.org/10.4018/JGIM.324813 229\nRouge Scores are [{'rouge-1': {'r': 1.0, 'p': 0.43966244725738396, 'f': 0.6107854588289521}, 'rouge-2': {'r': 0.9988888888888889, 'p': 0.349941611521993, 'f': 0.5183049831853369}, 'rouge-l': {'r': 1.0, 'p': 0.43966244725738396, 'f': 0.6107854588289521}}]\n","output_type":"stream"}]}]}